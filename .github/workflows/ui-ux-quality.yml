name: UI/UX Quality Checks

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'web/**'
      - '.github/workflows/ui-ux-quality.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'web/**'
      - '.github/workflows/ui-ux-quality.yml'

env:
  NODE_VERSION: '18'
  WEB_DIR: './web'

jobs:
  # Code Style & Design Rules
  code-style:
    name: Code Style & Design Rules
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WEB_DIR }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ${{ env.WEB_DIR }}/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Run ESLint (JS/TS)
      run: npm run lint

    - name: Fix ESLint issues (if possible)
      run: npm run lint:fix || true

    - name: Run Stylelint (CSS)
      run: npm run stylelint

    - name: Fix Stylelint issues (if possible)
      run: npm run stylelint:fix || true

    - name: Validate design tokens
      run: npm run design-tokens

    - name: Check for hardcoded colors/spacings
      run: |
        echo "Checking for hardcoded colors..."
        if grep -r "#[0-9a-fA-F]\{3,6\}" src/ --exclude-dir=node_modules; then
          echo "âŒ Found hardcoded hex colors. Use design tokens instead."
          exit 1
        fi
        echo "âœ… No hardcoded colors found"
        
        echo "Checking for hardcoded spacing..."
        if grep -r "margin\|padding\|gap" src/ --include="*.css" --include="*.scss" | grep -E "[0-9]+px"; then
          echo "âŒ Found hardcoded pixel values. Use design tokens instead."
          exit 1
        fi
        echo "âœ… No hardcoded spacing found"

  # Accessibility (a11y)
  accessibility:
    name: Accessibility Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WEB_DIR }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ${{ env.WEB_DIR }}/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Build application
      run: npm run build

    - name: Start preview server
      run: npm run preview &
      env:
        PORT: 8080

    - name: Wait for server
      run: npx wait-on http://localhost:8080 --timeout 30000

    - name: Run pa11y accessibility tests
      run: npm run a11y
      continue-on-error: true

    - name: Run axe-core accessibility tests
      run: |
        npx playwright test tests/e2e/accessibility.spec.ts --reporter=list
      continue-on-error: true

    - name: Upload accessibility results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: accessibility-results
        path: |
          ${{ env.WEB_DIR }}/pa11y-screenshots/
          ${{ env.WEB_DIR }}/playwright-report/

  # Visual Consistency
  visual-regression:
    name: Visual Regression Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WEB_DIR }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ${{ env.WEB_DIR }}/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Install Playwright browsers
      run: npx playwright install --with-deps

    - name: Build application
      run: npm run build

    - name: Run visual regression tests
      run: npm run visual-regression
      env:
        PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}
      continue-on-error: true

    - name: Upload visual regression results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: visual-regression-results
        path: |
          ${{ env.WEB_DIR }}/test-results/
          ${{ env.WEB_DIR }}/playwright-report/

  # UX Quality / Best Practices
  lighthouse:
    name: Lighthouse Performance & UX
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WEB_DIR }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ${{ env.WEB_DIR }}/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Build application
      run: npm run build

    - name: Start preview server
      run: npm run preview &
      env:
        PORT: 8080

    - name: Wait for server
      run: npx wait-on http://localhost:8080 --timeout 30000

    - name: Run Lighthouse CI
      run: npm run lighthouse
      continue-on-error: true

    - name: Upload Lighthouse results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: lighthouse-results
        path: ${{ env.WEB_DIR }}/lighthouse-results/

  # Component Contracts
  component-tests:
    name: Component Tests & Storybook
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WEB_DIR }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ${{ env.WEB_DIR }}/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Run unit tests
      run: npm run test:coverage

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ${{ env.WEB_DIR }}/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

    - name: Build Storybook
      run: npm run build-storybook

    - name: Validate Storybook stories
      run: |
        echo "Validating Storybook stories..."
        if [ ! -d "storybook-static" ]; then
          echo "âŒ Storybook build failed"
          exit 1
        fi
        
        # Check for required stories
        required_stories=("Button" "Input" "Modal" "Table" "Form")
        for story in "${required_stories[@]}"; do
          if ! find src/ -name "*.stories.tsx" -exec grep -l "$story" {} \; | grep -q .; then
            echo "âŒ Missing required story: $story"
            exit 1
          fi
        done
        echo "âœ… All required stories found"

    - name: Upload Storybook build
      uses: actions/upload-artifact@v4
      with:
        name: storybook-build
        path: ${{ env.WEB_DIR }}/storybook-static/

  # Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ env.WEB_DIR }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ${{ env.WEB_DIR }}/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Install Playwright browsers
      run: npx playwright install --with-deps

    - name: Build application
      run: npm run build

    - name: Run E2E tests
      run: npm run test:e2e
      env:
        CI: true

    - name: Upload E2E results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-results
        path: |
          ${{ env.WEB_DIR }}/test-results/
          ${{ env.WEB_DIR }}/playwright-report/

  # Quality Gate
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [code-style, accessibility, visual-regression, lighthouse, component-tests, integration-tests]
    if: always()
    
    steps:
    - name: Check all jobs status
      run: |
        echo "## ðŸŽ¯ UI/UX Quality Gate Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check each job status
        jobs=("code-style" "accessibility" "visual-regression" "lighthouse" "component-tests" "integration-tests")
        all_passed=true
        
        for job in "${jobs[@]}"; do
          status="${{ needs.$job.result }}"
          if [ "$status" = "success" ]; then
            echo "âœ… **$job**: Passed" >> $GITHUB_STEP_SUMMARY
          elif [ "$status" = "failure" ]; then
            echo "âŒ **$job**: Failed" >> $GITHUB_STEP_SUMMARY
            all_passed=false
          elif [ "$status" = "skipped" ]; then
            echo "â­ï¸ **$job**: Skipped" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **$job**: $status" >> $GITHUB_STEP_SUMMARY
            all_passed=false
          fi
        done
        
        echo "" >> $GITHUB_STEP_SUMMARY
        if [ "$all_passed" = true ]; then
          echo "ðŸŽ‰ **All UI/UX quality checks passed!**" >> $GITHUB_STEP_SUMMARY
        else
          echo "ðŸš¨ **Some UI/UX quality checks failed. Please review the results.**" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi

    - name: Upload combined results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ui-ux-quality-results
        path: |
          ${{ env.WEB_DIR }}/coverage/
          ${{ env.WEB_DIR }}/lighthouse-results/
          ${{ env.WEB_DIR }}/pa11y-screenshots/
          ${{ env.WEB_DIR }}/playwright-report/
          ${{ env.WEB_DIR }}/storybook-static/
